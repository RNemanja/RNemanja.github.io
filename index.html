<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Nemanja Rakicevic's web presentation">
    <meta name="keywords" content="nemanja, rakicevic, robotics, machine learning" />
    <meta name="author" content="Nemanja Rakicevic">
    <link rel="icon" href="./img/hal9000.ico">

    <title>Nemanja</title>

    <!-- Bootstrap Core CSS -->
    <!-- <link href="./vendor/bootstrap/css/bootstrap.css" rel="stylesheet"> -->
    <link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet">

    <!-- Theme CSS -->
    <link href="./css/freelancer.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <!-- <link href="./vendor/font-awesome/css/font-awesome.css" rel="stylesheet" type="text/css"> -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css" rel="stylesheet" type="text/css">

    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href="http://fonts.googleapis.com/css?family=Satisfy:300,400,700" rel="stylesheet" type="text/css">


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body id="page-top" class="index">

    <!-- Navigation -->
    <nav id="mainNav" class="navbar navbar-default navbar-fixed-top navbar-custom">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span> Menu <i class="fa fa-bars"></i>
                </button>
                <a class="navbar-brand" href="#page-top"><strong>Nemanja</strong> Rakićević <span class="homep">homepage</span></a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <li class="page-scroll">
                        <a href="#portfolio">Portfolio</a>
                    </li>
                    <li class="page-scroll">
                        <a href="#about">Publications</a>
                    </li>
                    <li class="page-scroll">
                        <a href="#stuff">Stuff</a>
                    </li>
                    <li class="page-scroll">
                        <a href="#social">Social</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
    </nav>

    <!-- Header -->
    <header>
      <div class="container">
        <div class="row">
          <div class="col-lg-12">

            <div class="person1" style="float:left; display:inline-block; ">
                <span style="float:left; width: 40%; padding-top: 3cm;">
                        <img class="img-responsive" src="./img/nemanja_munich.png"  
                         width="560" height"1000" alt="" align="left" />
                        <!-- <img class="img-responsive" src="./img/lagodicomo2.jpg"  
                         width="560" height"1000" alt="" align="left" /> -->
                       
                       <div class="col-lg-8 col-lg-offset-2 text-center">
                          <a href="./files/NemanjaRakicevic_CV.pdf" class="btn btn-lg btn-outline">
                              <!-- <i class="fa fa-file-text"></i>  -->
                              CV
                          </a>
                        </div>
                        
                </span>

<span style="float:left;width: 5%;">
</span>  

                <span style="float:right;width: 55%;">
                      <p style="float:right; display:block;">
                            <div class="intro-text">
                              <h1>about me:</h1>
                                <hr class="star-light">
                                    <span class="skills">
                                        I am a PhD candidate at the <a href="http://www.imperial.ac.uk/robot-intelligence/">Robot Intelligence Lab</a>, Imperial College London, under the supervision of <a href="http://kormushev.com/">prof Petar Kormushev</a>.
                                        <br>
                                        <br>
                                        My research interests lie at the intersection of artificial intelligence and robotics. 
                                        <br>
                                        Long term goal: developing a generic, hardware-independent algorithm, which would perform automatic system identification and self-supervised task learning. 
                                        <br>
                                        In the meantime: focusing on uncertainty-based efficient exploration approaches for supervised and reinforcement learning methods, applied to robotic task learning.
                                        <!-- More specifically machine learning methods for model-free robot control and intelligent interaction in unknown environments. -->

                                        <br>
                                        <br>
                                        I obtained my BSc degree in Mechatronics Robotics and Automation, at the Faculty of Technical Sciences, University of Novi Sad in 2011. Afterwards, I completed the double-degree <a href="http://emaro.irccyn.ec-nantes.fr/">EMARO</a>  (European Masters on Advanced Robotics) program and was awarded the MSc degree in 2013. 
                                        <br>
                                        During 2013-2014, I worked as a research engineer in <a href="https://www.laas.fr/public/en/ris">RIS group</a>, LAAS-CNRS Toulouse on rover locomotion diagnostics using sequential machine learning models.
                                        In 2015-2016, I was as a research assistant in the <a href="http://ibug.doc.ic.ac.uk/">iBug group</a>, Dept. of Computing, Imperial College London. There I worked on applying deep learning methods for human emotion recognition based on multimodal data, i.e. facial expressions and speech.        
                                  </span>
                            </div>
                      </p>
                </span>
            </div> 

          </div>
        </div>
      </div>
    </header>

    <!-- Portfolio Grid Section -->
    <section id="portfolio">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>Portfolio</h2>
                    <hr class="star-primary">
                </div>
            </div>
            <div class="row">
                <!-- Sentiment analysis -->
                <div class="col-sm-4 portfolio-item">
                    <a href="#portfolioModal1" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="./img/portfolio/p7_ibug.png" class="img-responsive" alt="">
                    </a>
                </div>
                <!-- "Mana" rover -->
                <div class="col-sm-4 portfolio-item">
                    <a href="#portfolioModal2" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="./img/portfolio/p6_laas.png" class="img-responsive" alt="">
                    </a>
                </div>
                <!-- "Cuatro" rover -->
                <div class="col-sm-4 portfolio-item">
                    <a href="#portfolioModal3" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="./img/portfolio/p5_keio_2.png" class="img-responsive" alt="">
                    </a>
                </div>
                <!-- NURC SAUC-E -->
                <div class="col-sm-4 portfolio-item">
                    <a href="#portfolioModal4" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="./img/portfolio/p4_nurc.png" class="img-responsive" alt="">
                    </a>
                </div>
                <!-- AI chasing game -->
                <div class="col-sm-4 portfolio-item">
                    <a href="#portfolioModal5" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="./img/portfolio/p3_game.png" class="img-responsive" alt="">
                    </a>
                </div>
                <!-- EUROBOT 2011 -->
                <div class="col-sm-4 portfolio-item">
                    <a href="#portfolioModal6" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="./img/portfolio/p2_eurobot.png" class="img-responsive" alt="">
                    </a>
                </div>
                <!-- Mini rover with gripper -->
                <div class="col-sm-4 portfolio-item">
                    <a href="#portfolioModal7" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="./img/portfolio/p1_imp.png" class="img-responsive" alt="">
                    </a>
                </div>
            </div>
        </div>
    </section>

    <!-- Publications Section -->
    <section class="success" id="about">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>Publications</h2>
                    <hr class="star-light">
                </div>
            </div>
            <div class="row">
                <div  id="ref">
            <!-- <p> -->
              
              <!-- TOP STICKS TO TOP OF PAGE -->
              <!-- <p class="sticktop" <a href="#top"><strong>TOP</strong></a></p> -->

              <br>
              <h2>2017 
              <!-- <a href="#top"><strong>TOP</strong></a> -->
              </h2>
                <ul>
                  <li>
                    <h4>Efficient Robot Task Learning and Transfer via Informed Search in Movement Parameter Space</h4>
                      <p>N. Rakicevic and P. Kormushev. Workshop on Acting and Interacting in the Real World: Challenges in Robot Learning (AIRW), (NIPS'17)</p>
                      <a id="reflink" href="./files/2017_AIRW.pdf">[pdf]<em class="ref"></em></a>
                      <a id="reflink" onclick="$('#11c203d9e2c82318044f0613_bibtex').toggle('')">[bibtex]<em class="ref"></em></a>
                      <!-- <a id="reflink" onclick="$('#55c203d9e2c82318044f0613_endnote).toggle('')">[endnote]<em class="ref"></em></a> -->
                                
                      <div class="reference" id="11c203d9e2c82318044f0613_bibtex" style="display: none;">
                        <div class="header">Bibtex reference <a id="reflink" onclick="$('#11c203d9e2c82318044f0613_bibtex').toggle('')">[hide]</a></div>
                        <div class="ref">
                          <pre>
@inproceedings{Rakicevic2017,
author = {N. Rakicevic and P. Kormushev},
booktitle = {Workshop on Acting and Interacting in the Real World: Challenges in Robot Learning, 31st Conference on Neural Information Processing Systems},
title = {Efficient Robot Task Learning and Transfer via Informed Search in Movement Parameter Space},
year = {2017},}
                          </pre>
                        </div>
                      </div>   
                                
                      <!-- <div class="reference" id="55c203d9e2c82318044f0613_endnote" style="display: none;">
                        <div class="header">Endnote reference <a id="reflink" onclick="$('#55c203d9e2c82318044f0613_endnote').toggle('')">[hide]</a></div>
                          <div class="ref">
                            <pre>
%0 Conference Proceedings
%T Multi-Modal Neural Conditional Ordinal Random Fields for Agreement Level Estimation
%A Rakicevic, N.
%A Rudovic, O.
%A Petridis, S.
%A Pantic, M.
%B International Conference on Pattern Recognition (ICPR'16)
%D 2016
%8 December
%C Cancun, Mexico
%F Rakicevic2016
                            </pre>
                          </div>
                      </div> -->
                          
                                
                  </li>

                </ul>

              <br>
              <br>
              <br>
              <br>
              <h2>2016 
              <!-- <a href="#top"><strong>TOP</strong></a> -->
              </h2>
                <ul>
                  <li>
                    <h4>Multi-modal Neural Conditional Ordinal Random Fields for  Agreement Level Estimation</h4>
                      <p>N. Rakicevic, O. Rudovic, S. Petridis and M. Pantic. International Conference on Pattern Recognition (ICPR’16)</p>
                      <a id="reflink" href="./files/2016_ICPR.pdf">[pdf]<em class="ref"></em></a>
                      <a id="reflink" onclick="$('#55c203d9e2c82318044f0613_bibtex').toggle('')">[bibtex]<em class="ref"></em></a>
                      <!-- <a id="reflink" onclick="$('#55c203d9e2c82318044f0613_endnote).toggle('')">[endnote]<em class="ref"></em></a> -->
                                
                      <div class="reference" id="55c203d9e2c82318044f0613_bibtex" style="display: none;">
                        <div class="header">Bibtex reference <a id="reflink" onclick="$('#55c203d9e2c82318044f0613_bibtex').toggle('')">[hide]</a></div>
                        <div class="ref">
                          <pre>
@inproceedings{Rakicevic2016,
author = {N. Rakicevic and O. Rudovic and S. Petridis and M. Pantic},
address = {Cancun, Mexico},
booktitle = {International Conference on Pattern Recognition (ICPR’16)},
month = {December},
title = {Multi-Modal Neural Conditional Ordinal Random Fields for Agreement Level Estimation},
year = {2016},}
                          </pre>
                        </div>
                      </div>   
                                
                      <!-- <div class="reference" id="55c203d9e2c82318044f0613_endnote" style="display: none;">
                        <div class="header">Endnote reference <a id="reflink" onclick="$('#55c203d9e2c82318044f0613_endnote').toggle('')">[hide]</a></div>
                          <div class="ref">
                            <pre>
%0 Conference Proceedings
%T Multi-Modal Neural Conditional Ordinal Random Fields for Agreement Level Estimation
%A Rakicevic, N.
%A Rudovic, O.
%A Petridis, S.
%A Pantic, M.
%B International Conference on Pattern Recognition (ICPR'16)
%D 2016
%8 December
%C Cancun, Mexico
%F Rakicevic2016
                            </pre>
                          </div>
                      </div> -->
                          
                                
                  </li>

                </ul>

              <br>
              <br>
              <br>
              <br>
              <h2>2015
              <!-- <a href="#top"><strong>TOP</strong></a>-->
              </h2>
              <ul>
                  <li>
                    <h4>Neural Conditional Ordinal Random Fields for  Agreement Level Estimation</h4>
                      <p>N. Rakicevic, O. Rudovic, S. Petridis and M. Pantic. 1st International Workshop on Automatic Sentiment Analysis in the Wild (WASA’15), ACII&#39;15</p>
                      <a id="reflink" href="./files/2015_WASA.pdf">[pdf]<em class="ref"></em></a>
                      <a id="reflink" onclick="$('#55bf82af02bbb0c00154cd16_bibtex').toggle('')">[bibtex]<em class="ref"></em></a>
                      <!-- <a id="reflink" onclick="$('#55bf82af02bbb0c00154cd16_endnote').toggle('')">[endnote]<em class="ref"></em></a> -->
                                
                      <div class="reference" id="55bf82af02bbb0c00154cd16_bibtex" style="display: none;">
                        <div class="header">Bibtex reference <a id="reflink" onclick="$('#55bf82af02bbb0c00154cd16_bibtex').toggle('')">[hide]</a></div>
                        <div class="ref">
                          <pre>
@inproceedings{Rakicevic2015,
author = {N. Rakicevic and O. Rudovic and S. Petridis and M. Pantic},
address = {Xi&#39;an, China},
booktitle = {1st International Workshop on Automatic Sentiment Analysis in the Wild (WASA’15)},
month = {September},
title = {Neural Conditional Ordinal Random Fields for Agreement Level Estimation},
year = {2015},}
                          </pre>
                        </div>
                      </div>   
                                
                      <!-- <div class="reference" id="55bf82af02bbb0c00154cd16_endnote" style="display: none;">
                        <div class="header">Endnote reference <a id="reflink" onclick="$('#55bf82af02bbb0c00154cd16_endnote').toggle('')">[hide]</a></div>
                          <div class="ref">
                            <pre>
%0 Conference Proceedings
%T Neural Conditional Ordinal Random Fields for Agreement Level Estimation
%A Rakicevic, N.
%A Rudovic, O.
%A Petridis, S.
%A Pantic, M.
%B 1st International Workshop on Automatic Sentiment Analysis in the Wild (WASA’15)
%D 2015
%8 September
%C Xi&#39;an, China
%F Rakicevic2015
                            </pre>
                          </div>
                      </div> -->
                                
                  </li>

                </ul>

          </div>
                <!-- <div class="col-lg-4 col-lg-offset-2">
                    <p>Freelancer is a free bootstrap theme created by Start Bootstrap. The download includes the complete source files including HTML, CSS, and JavaScript as well as optional LESS stylesheets for easy customization.</p>
                </div>
                <div class="col-lg-4">
                    <p>Whether you're a student looking to showcase your work, a professional looking to attract clients, or a graphic artist looking to share your projects, this template is the perfect starting point!</p>
                </div> -->
                <!-- <div class="col-lg-8 col-lg-offset-2 text-center">
                    <a href="#" class="btn btn-lg btn-outline">
                        <i class="fa fa-download"></i> Download Theme
                    </a>
                </div> -->
            </div>
        </div>
    </section>

    <!-- Contact Section -->
    <section id="stuff">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>Stuff</h2>
                    <hr class="star-primary">
                </div>
            </div>
            <div class="row">

              <!-- ML BLOG -->
              <h3>
                ML Blog [wip]
              </h3>
              <ul>
                  <!-- Entropy -->
                  <li>
                    <h4><a href="https://stats.stackexchange.com/questions/87182/what-is-the-role-of-the-logarithm-in-shannons-entropy">About Entropy and Cross-Entropy Cost Function</a></h4>
                  </li>
                  <!-- MLE & MAP-->
                  <li>
                    <h4><a href="https://wiseodd.github.io/techblog/2017/01/01/mle-vs-map/">About Maximum Likelihood Estimation (MLE) and Maximum A Posteriori (MAP) Estimation</a></h4>
                  </li>
                  <!-- Maximum Entropy Principle -->
                  <li>
                    <h4><a href="http://www-mtl.mit.edu/Courses/6.050/2003/notes/chapter9.pdf">About Maximum Entropy Principle</a></h4>
                  </li>
                  <!-- Hilbert spaces and Kernels-->
                  <li>
                    <h4><a href="https://datascience.stackexchange.com/questions/9302/the-cross-entropy-error-function-in-neural-networks">From Hilbert Spaces, via Kernels to SVMs and GPs</a></h4>
                  </li>
              </ul>

              <br>

              <!-- RL Blog-->
              <h3>
                RL Blog
              </h3>
              <ul>
                  <!-- NOTE: Most of blogs that try to explain RL approaches somehow either explain concepts on a very low level and/or just jump in to complicated Deep examples. Research papers usually just explain concepts on a high level with maybe some pseudocode which is not straightforward to implement. Code implementations on GitHub are usually made to be self-contained and are complicated/require a lot of time to actually find basic examples. These are the reasons why I decided to make a basic step-by-step introduction, as well as to make a reminder for myself. Also, I needed to practice converting EQUATIONS to CODE. -->
                  <!-- Policy Gradients -->
                  <li>
                    <h4><a href="./html_files/blog_policy_gradient.html">Policy Gradient, an explaination. [wip]</a></h4>
                  </li>
              </ul>

              <br>

              <!-- Useful Resources -->
              <h3>
                Miscellaneous stuff
              </h3>
              <ul>
                  <li>
                    <h4><a href="https://blog.scottlowe.org/2015/01/27/using-fork-branch-git-workflow/">GitHub branching workflow</a></h4>
                  </li>
                  <li>
                    <h4><a href="https://nips.cc/Conferences/2015/PaperInformation/EvaluationCriteria">
                      Writing a good paper</a></h4>
                  </li>
              </ul>

            </div>
        </div>
    </section>

    <!-- Footer -->
    <!-- http://astronautweb.co/snippet/font-awesome/ -->

    <section id="social">
      <footer class="text-center">
          <div class="footer-above">
              <div class="container">
                  <div class="row">
                      <!-- <div class="footer-col col-md-4">
                          <h3>Location</h3>
                          <p>3481 Melrose Place
                              <br>Beverly Hills, CA 90210</p>
                      </div> -->
                      <div class="footer-col col-md-4">
                          <h3>Social</h3>
                          <ul class="list-inline">
                              <li>
                                  <a href="https://github.com/nemanja-rakicevic" class="btn-social btn-outline"><i class="fa fa-fw fa-github"></i></a>
                              </li>
                              <li>
                                  <a href="https://uk.linkedin.com/in/nemanja-rakicevic-390b3330" class="btn-social btn-outline"><i class="fa fa-fw fa-linkedin"></i></a>
                              </li
                              <li>
                                  <a href="https://plus.google.com/u/0/107672761183071517394" class="btn-social btn-outline"><i class="fa fa-fw fa-google-plus"></i></a>
                              </li>
                              <li>
                                  <a href="https://twitter.com/nrkcv" class="btn-social btn-outline"><i class="fa fa-fw fa-twitter"></i></a>
                              </li>
                              <li>
                                  <a href="https://www.facebook.com/nemanja.rakicevic" class="btn-social btn-outline"><i class="fa fa-fw fa-facebook"></i></a>
                              </li>
                          </ul>
                      </div>
                      <!-- <div class="footer-col col-md-4">
                          <h3>About Freelancer</h3>
                          <p>Freelance is a free to use, open source Bootstrap theme created by <a href="http://startbootstrap.com">Start Bootstrap</a>.</p>
                      </div> -->
                  </div>
              </div>
          </div>
          <div class="footer-below">
              <div class="container">
                  <div class="row">
                      <div class="col-lg-12">
                          Copyright &copy; NR 2016 [Last updated 01/2018]
                      </div>
                  </div>
              </div>
          </div>
      </footer>
    </section>

    <!-- Scroll to Top Button (Only visible on small and extra-small screen sizes) -->
    <div class="scroll-top page-scroll visible-sm hidden-xs visible-lg visible-md">
        <a class="btn btn-primary" href="#page-top">
            <i class="fa fa-chevron-up"></i>
        </a>
    </div>

    <!-- Portfolio Modals -->

                <!-- Sentiment analysis -->
    <div class="portfolio-modal modal fade" id="portfolioModal1" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <h2>Sentiment Analysis</h2>
                            <hr class="star-primary">
                            <img src="./img/portfolio/p7_ibug.png" class="img-responsive img-centered" alt="">
                            <p>
                                During my time in the intelligent behaviour understanding group (iBug) I have extended the sequential methods I started working on in LAAS (Conditional Random Fields) and applied them to human sentiment analysis based on facial expressions. 
                                More specifically, I have concentrated on inter-personal (dis)agreement intensity  analysis, based on visual and audio inputs.
                                Moreover, I obtained experience as a teaching assistant in the Machine Learning course (C395).
                            </p>
                            <p>
                                My work was financed from the <a href="http://sewaproject.eu/">SEWA project</a> whose goal is to exploit the state of the art machine learning approaches to the analysis of facial, vocal and verbal behaviour, which can be combined and applied to realise more natural human-computer interaction.
                            </p>
                            <p>
                                The first publication I made [Rakicevic et al. 2015] proposes a novel approach to automatic estimation of (dis)agreement intensity levels a person expresses during a dyadic conversation. 
                            </p>
                            <p>
                                The data used in for this purpose was obtained from the MAHNOB-Mimicry database [Sun et al 2011]. From this database, I used 34, 15min long, video recorded sessions of 38 different participants discussing various topics (money, television, books, smoking etc.). The recording setup is shown in the upper figure on the right. The videos have a frame rate of 58 frames per second. For the first model, only 5 subjects were used. 
                                The input features used are the tracked facial points’ positions (49 points) 
                                obtained using the face tracker from [Ashtana et al. 2014]
                            </p>
                            <p>
                                The (dis)agreement intensity labels were defined according
                                 to the Likert ordinal scale [Likert 1932] in the range:
                                <li>2 : Strong Disagreement</li>
                                <li>-1 : Disagreement</li>
                                <li>0 : Neutral level</li>
                                <li>+1 : Agreement</li>
                                <li>+2 : Strong Agreement</li>
                            </p>
                            <p>    
                                The annotation was performed per-frame by an expert annotator. 
                                The final distribution of the intensity levels is shown in the lower figure.
                            </p>
                            <img src="./img/portfolio_data/ibug1.png" class="img-responsive img-centered" alt="">
                            <img src="./img/portfolio_data/ibug2.png" class="img-responsive img-centered" alt="" >
                            <p>
                                After appropriate feature pre-processing (alignment and normalisation), down-sampling and segmentation, 329 sequences were obtained, on average 80 frames long. 5 fold subject-independent cross validation of the compared models.
                            </p>
                            <p>
                                The model we proposed, Neural Conditional Ordinal Random Field model, performs non-linear feature extraction from face images using the notion of Neural Networks (NN), while also modelling temporal and ordinal relationships between the agreement levels by means of a Conditional Ordinal Random Field (CORF) model [Kim and Pavlovic 2010]. The model structure is presented in the figure below.
                            </p>
                            <img src="./img/portfolio_data/ibug3.png" class="img-responsive img-centered" alt="">
                            <p>
                                The model’s performance was compared with static (NN and Support Vector Machines)  and sequential (CRF) baseline, as well as state of the art models (CORF and Kernel CORF). Moreover, we cross-validated the architecture of the NN part and the best results are obtained for 10 hidden nodes.
                                We show in our experiments that the proposed approach outperforms existing methods for modelling of sequential data. The measures used were the F1 score, Mean Absolute Error (MAE) and Intra-Class Correlation Coefficient (ICC).
                            </p>
                            <img src="./img/portfolio_data/ibug4.png" class="img-responsive img-centered" alt="">
                            <img src="./img/portfolio_data/ibug5.png" class="img-responsive img-centered" alt="">
                            <p>
                                MULTIMODAL EXTENSION
                                <br>
                                The multimodal extensions employs facial features, as previously, and also audio features, extracted from the person in focus’ active speech segments. The 130 audio features used are the 65 described in [Schuller et al. 2013] and their derivatives. The extraction was done using the OpenSMILE software [Eyben et al. 2013].
                                The second contribution is the 2-phase joint decoupled optimisation of the NN and CORF parameters. This decoupled approach is proposed to avoid the slow learning which occurs when all the parameters are optimised together.
                                Moreover, in this work, all 38 participants were included.
                            </p>
                            <img src="./img/portfolio_data/ibug6.png" class="img-responsive img-centered" alt="">
                            <p>
                                The proposed model diagram is presented in the figure above. This is still work in progress.
                                Further extensions would include employing CNNs to raw pixel inputs instead of tracked point positions.
                            </p>


                            <ul class="list-inline item-details">
                                <li>Institution:
                                    <strong><a href="http://ibug.doc.ic.ac.uk/">iBug, Imperial College London</a>
                                    </strong>
                                </li>
                                <li>Date:
                                    <strong><a href="#">2014-2015</a>
                                    </strong>
                                </li>
                                <li>Supervisor:
                                    <strong><a href="http://ibug.doc.ic.ac.uk/people/mpantic">Maja Pantić</a>
                                    </strong>
                                </li>
                            </ul>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
                <!-- "Mana" rover -->
    <div class="portfolio-modal modal fade" id="portfolioModal2" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <h2>"Mana" rover</h2>
                            <hr class="star-primary">
                            <img src="./img/portfolio/p6_laas.png" class="img-responsive img-centered" alt="">
                            <p>
                                The work done here was a preliminary analysis of rover locomotion and diagnostics for various terrain types (grass, rocks, asphalt) and different locomotion classes (nominal, rough, failure). This was a preparatory study supposed to be further extended into a PhD thesis “Agile Locomotion for a Planetary Rover”, in collaboration with Astrium <a href="http://www.astrium.eads.net/">Astrium</a> and <a href="http://www.esa.int">ESA</a>. Unfortunately, Astrium went under restructuring and was unable to finance it.
                            </p>
                            <p>
                                The motivation lies in the fact that the chassis of planetary rovers is conceived to endow them with high locomotion capabilities, however the classical navigation loops considered for now (and in the near future, e.g. for the Exomars rover) are defined so that even small obstacles must be circumnavigated. There is however a big interest in empowering such rovers with obstacle-crossing capabilities, from an operational point of view on the one hand, but also from the scientific point (collecting more interesting samples) on the other hand, as this remains an open challenging problem. 
                                Planetary exploration is just an example application, the work would also pertain to any robot with advanced locomotion capabilities, such as in search and rescue applications for instance.
                            </p>
                            <p>
                                CHALLENGES
                                <br>

                                <li>
                                    Such a locomotion ability would require a thorough re-visit of the navigation loop, with a very strong focus on locomotion control: when trying to climb a pile of rocks for instance, the 3D model built is of little help as many areas remain occluded (due to the terrain geometry and the angle from which range data is acquired), and also because when driving on such areas, the ground below the wheels is "moving“ (rocks are rolling, wheels are slipping, etc.)
                                </li>

                                <li>
                                    One of the most difficult issues is that the knowledge of the wheel/soil interactions is very poor. Hence, a challenge is to derive such knowledge as much as possible from all the parameters that can be sensed on-board the rover (from wheel current consumption to overall position and speed, via all the encoders information, terrain analysis or even sound). 
                                </li>
                            </p>
                            <p>
                                A “diagnosis” capability is also a part of the problem. A “classic” example is when the Opportunity rover got stuck in a loose sand dune, back in April 2005, it took 5 weeks for NASA engineers to free the rover. There were many options to detect and prevent this (e.g. wheel slippage detection, even without comparison with visual odometry), the problem was that the loose sand had no visual print, and at that time they had already traversed a few kilometers on this monotonic environment, looking forward to reach Victoria crater.. This actually pertains more to locomotion diagnostic (or monitoring), but still is something which is part of "agile locomotion".
                            </p>
                            <p>
                                Work done at LAAS consisted of gathering and analysing the data using the “Mana” rover
                            </p>
                            <img src="./img/portfolio_data/laas1.png" class="img-responsive img-centered" alt="">
                            <p>
                                <ul>
                                    <li>Inputs from sensors gathered </li>
                                    <ul> 
                                      <li>Velocity, torque, IMU...</li>
                                    </ul>
                                </ul>

                                <ul>
                                    <li>
                                      Labeling by expert annotator 
                                    </li>
                                    <ul> 
                                      <li>3 classes (normal, rough and fault locomotion)
                                      </li>
                                    </ul>
                                </ul>

                                <ul>
                                    <li>
                                      Machine Learning modelling methods explored 
                                    </li>
                                    <ul> 
                                      <li>Conditional Random Fields (CRF), Hidden Markov Models (HMM), Naive Bayes…
                                      </li>
                                    </ul>
                                </ul>
                                
                            </p>
                            <p>
                                Due to the limited amount of time, the analysis of results was not completed. However, based on the obtained feature-label distributions the problem seems to be complex, but interesting for further examination.
                            </p>
                            <p>
                                Label distribution in the space of front - back wheel velocity and torque difference:
                            </p>
                            <img src="./img/portfolio_data/laas2_vel.png" class="img-responsive img-centered" alt="">
                            <img src="./img/portfolio_data/laas2_torque.png" class="img-responsive img-centered" alt="">
                            <p>
                                Label distribution in the space of left – right wheel velocity and torque difference:
                            </p>
                            <img src="./img/portfolio_data/laas3_vel.png" class="img-responsive img-centered" alt="">
                            <img src="./img/portfolio_data/laas3_torque.png" class="img-responsive img-centered" alt="">

                            <ul class="list-inline item-details">
                                <li>Institution:
                                    <strong><a href="https://www.laas.fr/public/fr/ris/">RIS, LAAS</a>
                                    </strong>
                                </li>
                                <li>Date:
                                    <strong><a href="#">2013-2014</a>
                                    </strong>
                                </li>
                                <li>Supervisor:
                                    <strong><a href="https://homepages.laas.fr/simon/HomePage/Home.html">Simon Lacroix</a>
                                    </strong>
                                </li>
                            </ul>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
                <!-- "Cuatro" rover -->
    <div class="portfolio-modal modal fade" id="portfolioModal3" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <h2>"Cuatro" rover </h2>
                            <hr class="star-primary">
                            <img src="./img/portfolio/p5_keio_2.png" class="img-responsive img-centered" alt="">
                            <p>
                                For my master thesis, I have developed, implemented and performed experimental tests on the physical rover, for a fuzzy logic based navigation and terrain mapping algorithm. 
                            </p>
                            <p>
                                The rover used to test the code was  Japan Aerospace Exploration Agency’s (JAXA) test bed rover “Cuatro”. The 2 test sessions were done at the Institute of Space and Aeronautical Science (ISAS) rover laboratory, thanks to the help of prof Genya Ishigami. 
                            </p>
                            <p>
                                The algorithm performed good during the practical tests and I have defended my MSc thesis with the highest grade.
                            </p>
                            <p>
                                PROBLEM STATEMENT AND OBJECTIVE
                                <br>

                                <p>
                                  <ul>
                                    <li>Problem to be solved</li>
                                    <ul>
                                      <li>
                                          To deal with obstacles which are not considered during global path planning due to the dead area of external sensors and occlusions.
                                      </li>
                                      <li>
                                          Mapping the explored environment.
                                      </li>
                                    </ul>
                                
                                    <li>Objective</li>
                                    <ul>
                                      <li>
                                          To propose an efficient re-planning method considering sub-goals of the global path (their direction) and the spatial terrain properties (the state of the ground, the height and the distance from the untraversable obstacles and also the terrain roughness), in order to deal with the above problems.
                                      </li>
                                    </ul>
                                  </ul>
                                </p>
                            <img src="./img/portfolio_data/keio1.png" class="img-responsive img-centered" alt="">
                            <p>
                                Proposed Method:
                                <ul>
                                  <li>
                                    Global map generation from local views and position information.
                                  </li>
                                  <li>
                                    Fuzzy Controller based navigation based on local views.
                                  </li>
                                </ul>
                              </p>
                              <p>
                                Verification Tests on the “Cuatro” rover:
                                <ul>
                                  <li>Weight: 35kg</li>
                                  <li>4 wheel drive</li>
                                  <li>4 wheel steering</li>
                                  <li>SwissRanger™ SR4000  TOF camera</li>
                                  <li>Rocker suspension + independent shock absorbers</li>
                                </ul>
                            </p>
                            <br>
                            <p>
                                PROPOSED METHOD OVERVIEW
                                <br>
                                The diagram of the proposed algorithm shows the process from obtaining the short range image, through its integration in the global map (based on the robots position and attitude), up to the derivation and execution of the control variables (speed and direction) by the system.
                            </p>
                            <img src="./img/portfolio_data/keio2.png" class="img-responsive img-centered" alt="">
                            <p>
                                <li>
                                    INPUTS: roll, pitch, yaw angles; global x, y coordinates; short range camera image
                                </li>
                                <li>
                                    OUTPUTS: control variables for motion execution (desired speed and orientation)
                                </li>
                            </p>
                            <p>
                                MAPPING
                                <br>

                                The mapping was done by taking as input the short range camera image, applying necessary transformations to compensate for the robots pose, and then integrating it in the global map. This approach considers terrain roughness and not just a simple discrimination to traversable and untraversable obstacles.
                                <br>
                                Care has been taken to appropriately weigh the old and new information when combining with the existing map data.
                                <br>
                                The figure shows how the new transformed map patch is aligned and added to the global map.
                            </p>
                            <img src="./img/portfolio_data/keio3.png" class="img-responsive img-centered" alt="">
                            <p>
                                FUZZY CONTROLLER
                                <br>

                                The figure shows how the control output is derived 
                                based on the transformed short range input image.
                            </p>
                            <img src="./img/portfolio_data/keio4.png" class="img-responsive img-centered" alt="">
                            <p>
                                <li>
                                    OBSTACLE membership function is formed based on the distance of the untraversable obstacles
                                </li>
                                <li>
                                    GOAL membership function is a simple triangular function with its peak at the direction of the goal.
                                </li>
                            </p>
                            <p>
                                The above two are combined to get the final output control variables – speed coefficient and heading direction.
                            </p>
                            <p>
                                TESTING ON “CUATRO”: TEST 1 – follow sub-goals and avoid obstacle

                                <img src="./img/portfolio_data/keio_t1.png" class="img-responsive img-centered" alt="">
                                <iframe width="560" height="315" src="https://www.youtube.com/embed/ChR6Njm8jqg" frameborder="0" allowfullscreen></iframe>
                            </p>

                            <p>
                                TESTING ON “CUATRO”: TEST 2 – manage the occluded terrain

                                <img src="./img/portfolio_data/keio_t2.png" class="img-responsive img-centered" alt="">
                                <iframe width="560" height="315" src="https://www.youtube.com/embed/S2OBJ54oqQ8" frameborder="0" allowfullscreen></iframe>
                            </p>



                            <ul class="list-inline item-details">
                                <li>Institution:
                                    <strong><a href="http://www.yt.sd.keio.ac.jp/">Takahashi Lab, Keio University</a>
                                    </strong>
                                </li>
                                <li>Date:
                                    <strong><a href="#">2013</a>
                                    </strong>
                                </li>
                                <li>Supervisor:
                                    <strong><a href="http://www.yt.sd.keio.ac.jp/member.html">Masaki Takahashi</a>
                                    </strong>
                                </li>
                            </ul>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
                <!-- NURC SAUC-E -->
    <div class="portfolio-modal modal fade" id="portfolioModal4" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <h2>NURC SAUC-E </h2>
                            <hr class="star-primary">
                            <img src="./img/portfolio/p4_nurc.png" class="img-responsive img-centered" alt="">
                            <p>
                                For this project I was a part of a team of 5 people (Luca Buoncompagni, Raffaello Camoriano, Thomas Genevois and Gamal El Ghazaly). The purpose was to create and autonomous undewater vehicle (AUV) to compete at the 2012 <a href="http://sauc-europe.org/">NURC SAUC-E competition</a>.
                            </p>
                            <p>
                                My main responsibilities were the development and implementation, connection and testing of all electronic components, including: power convertors, sensor data A/D conversion, actuators’ drivers integration and wiring. The main challenge was to optimally organise and connect all component in a confined waterproof space.
                                Besides this, I collaborated with Thomas on the mechanical design and assembly of the overall structure.
                            </p>
                            <p>
                                THE ROBOT: CRISTOFORO
                                Initial CAD model with main components:
                            </p>

                            <img src="./img/portfolio_data/nurc1.png" class="img-responsive img-centered" alt="">
                            <p>
                                COMPONENTS
                                <br>
                                The components used in the AUV which needed to be organised:
                                <br>
                                <ul>
                                  <li>Power supply </li>
                                    <ul>
                                      <li>Batteries (4 Lithium-Polymer (LiPo), 6 cell, batteries)</li>
                                      <li>Emergency stop </li>
                                      <li>Power board </li>
                                    </ul>
                                  <li>Devices </li>
                                    <ul>
                                      <li>Sensors  (Doppler Velocity Log (DVL), Inertial Measurement Unit (IMU), hydrophones, top camera , webcam)</li>
                                      <li>Actuators (stepper motor and its controller, thruster motors and their drivers)</li>
                                      <li>Computation (PC104 and peripherals, Arduino)</li>
                                    </ul>
                                  <li>Connectors </li>
                                    <ul>
                                      <li>Waterproof connectors </li>
                                      <li>Molex: motors & pressure sensor </li>
                                      <li>Battery molex + special </li>
                                      <li>Camera + hydrophones</li>
                                    </ul>
                                  </ul>
                            </p>
                            <p>
                                Moreover, additional auxiliary structural components needed to be made to support all the devices. Particular care was taken when components were placed so they do not interfere and affect each others performance.
                            </p>
                            <p>
                                INSIDE THE TUBE
                                <br>
                                <li>
                                  Component placement inside the tube and their actual fitting:
                                </li>
                            </p>
                            <img src="./img/portfolio_data/nurc2.png" class="img-responsive img-centered" alt="">
                            <p>
                                OUTSIDE THE TUBE
                                <br>
                                <li>
                                    The biggest issue was ensuring the waterproofing of the tube, at its most vulnerable points – the connectors. The inside-outside connections were between the thrusters and their drivers. These connectors were custom made by putting motors’ large cables in the brass connector and sealing it off with a solidifying waterproof sealant.
                                </li>
                                <li>
                                    However, this was the weak point which made the most problems, and is the cause why our team did not manage to prepare the AUV in time for the challenge.
                                </li>
                            </p>
                            <img src="./img/portfolio_data/nurc3.png" class="img-responsive img-centered" alt="">
                            <p>
                                WIRING DIAGRAM
                            </p>
                            <img src="./img/portfolio_data/nurc4.png" class="img-responsive img-centered" alt="">
                            <p>
                                POWER BOARD
                                <br>
                                This is the power board that I designed and produced in order to provide specific voltage/current demands for each of the components it supplies.
                                Images with all connections attached and deployed in the tube are shown below:
                            </p>
                            <img src="./img/portfolio_data/nurc5.png" class="img-responsive img-centered" alt="">
                            <p>
                                CONNECTORS
                                <br>

                                The largest connectors which used up most of the space were the ones connecting the thrusters with their drivers. In order for the lid to be detachable, we used MOLEX connectors for easier attachment/detachment.
                            </p>
                            <img src="./img/portfolio_data/nurc6.png" class="img-responsive img-centered" alt="">
                            <p>
                                FINAL STRUCTURE
                            </p>
                            <img src="./img/portfolio_data/nurc7.png" class="img-responsive img-centered" alt="">
                            <iframe width="560" height="315" src="https://www.youtube.com/embed/A5jPsKnRdtY" frameborder="0" allowfullscreen></iframe>



                            <ul class="list-inline item-details">
                                <li>Institution:
                                    <strong><a href="https://www.unige.it/">Università degli studi di Genova</a>
                                    </strong>
                                </li>
                                <li>Date:
                                    <strong><a href="#">2012</a>
                                    </strong>
                                </li>
                                <li>Supervisor:
                                    <strong><a href="http://www.dibris.unige.it/en/casalino-giuseppe">Giuseppe Casalino</a>
                                    </strong>
                                </li>
                            </ul>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
                <!-- AI chasing game -->
    <div class="portfolio-modal modal fade" id="portfolioModal5" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <h2>AI chasing game</h2>
                            <hr class="star-primary">
                            <img src="./img/portfolio/p3_game.png" class="img-responsive img-centered" alt="">
                            <p>
                                The goal of the project was to build a multithreaded program in C. This simulates a mobile robot (“robber”) that is supposed to find a way through an unknown environment (binary maze), while avoiding hostile agents for a certain amount of time. There are 2 types of hostile agents - “policeman” and “ninja”. The former moves in a pseudo-random fashion through the map, while the latter is actively searching for the “robber”.
                            </p>
                            <p>
                                The algorithm is based on a potential field approach. The “robber” is repulsed by the hostile agents, and attracted to a specific position on the map. Conversely, the “ninja” is attracted by the “robber” and tries to catch it.
                            </p>
                            <p>
                                The project was done with 3 colleagues (Claudio Giovanni, Marsano Matilde and Vassallo Christian). My responsibility was the implementation of the above mentioned algorithm.
                            </p>
                            <iframe width="560" height="315" src="https://www.youtube.com/embed/Zs_VY33J9Zw" frameborder="0" allowfullscreen></iframe>

                            <ul class="list-inline item-details">
                                <li>Institution:
                                    <strong><a href="https://www.unige.it/">Università degli studi di Genova</a>
                                    </strong>
                                </li>
                                <li>Date:
                                    <strong><a href="#">2012</a>
                                    </strong>
                                </li>
                                <li>Supervisor:
                                    <strong><a href="http://www.elka.pw.edu.pl/pol/Wydzial/Pracownicy/Nauczyciele-akademiccy-WEiTI-1951-2011/K/Kubica-Bartlomiej-Jacek">Bartłomiej Kubica</a>
                                    </strong>
                                </li>
                            </ul>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
                <!-- EUROBOT 2011 -->
    <div class="portfolio-modal modal fade" id="portfolioModal6" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <h2>EUROBOT 2011</h2>
                            <hr class="star-primary">
                            <img src="./img/portfolio/p2_eurobot.png" class="img-responsive img-centered" alt="">
                            <p>
                                For this project, I was the team leader in a team of 5 people (Vasilije Anojčić, Stefan Vorkapić, Voislav Zec and Živko Crnojački). The goal was to create an autonomous mobile robot to participate in the <a href="http://www.eurobot2011.ru/">EUROBOT 2011</a> championship.
                            </p>
                            <p>
                                My responsibilities were:
                                <ul>
                                  <li>Work organisation and logistics</li>
                                  <li>Electronics (power, sensors, main microcontroller and wiring communication)</li>
                                  <li>Programming the main strategy algorithm</li>
                                  <li>Obtaining sponsorships and parts</li>
                                </ul>
                            </p>
                            
                            <p>
                                By the end of the project, we have produced a fully functioning, autonomous mobile robot, from scratch, which placed 6th (best in our generation) at the national qualifiers at which also senior teams and guest teams from abroad participated. 
                                <br>
                                The line-following system developed created the basis for my BSc thesis.
                            </p>
                            <p>
                                PLAYGROUND
                                <br>
                                <ul>
                                  <li>2 players</li>
                                  <li>Figures</li>
                                  <ul>
                                    <li>King</li>
                                    <li>Queen</li>
                                    <li>Pawn</li>
                                  </ul>
                                  <li>Blue & red fields</li>
                            </p>
                            <p>
                                MAIN CHALLENGES
                                <br>
                                <ul>
                                  <li>Recognising chess elements</li>
                                  <li>Avoiding fixed obstacles (table edges)</li>
                                  <li>Avoiding the opponent robot</li>
                                  <li>Line tracking</li>
                                </ul>
                            </p>
                            <img src="./img/portfolio_data/eurobot1.png" class="img-responsive img-centered" alt="">

                            <p>
                                ACTUATORS
                                <br>
                                Front actuators for gripping the chess elements
                                <img src="./img/portfolio_data/eurobot2.png" class="img-responsive img-centered" alt="">
                                <br>
                                Inner actuator for lifting the robot
                                <img src="./img/portfolio_data/eurobot3.png" class="img-responsive img-centered" alt="">
                            </p>

                            <p>
                                SENSORS
                                <br>
                                SHARP Infra-red distance sensors - used both for obstacle and opponent avoidance
                                <img src="./img/portfolio_data/eurobot4.png" class="img-responsive img-centered" alt="">
                                <br>
                                RGB colour sensor (HDJD-S822-QR999) -used for line following
                                <img src="./img/portfolio_data/eurobot5.png" class="img-responsive img-centered" alt="">
                            </p>
                            <p>
                                FINAL PRODUCT
                            </p>
                            <img src="./img/portfolio_data/eurobot6.png" class="img-responsive img-centered" alt="">

                            <p>
                                LINE FOLLOWING
                                <br>

                                The main concept behind the line following, is using the left and right RGB sensor couples to detect the edges. This can be exploited to compensate the encoder’s error accumulation due to slippage. The approach can be used for precise turning and correcting the motion by aligning the wheels on the edges.
                            </p>
                            <p>
                                Precise turning through alignment shown in 6 steps:
                            </p>
                            <img src="./img/portfolio_data/eurobot7.png" class="img-responsive img-centered" alt="">
                            <p>
                                LINE FOLLOWING
                                <br>

                                Straight motion by aligning to perpendicular edges and disturbance correction
                            </p>
                            <iframe width="560" height="315" src="https://www.youtube.com/embed/LYB5jWs84Cg" frameborder="0" allowfullscreen></iframe>




                            <ul class="list-inline item-details">
                                <li>Institution:
                                    <strong><a href="#">FTN, University of Novi Sad</a>
                                    </strong>
                                </li>
                                <li>Date:
                                    <strong><a href="#">2011</a>
                                    </strong>
                                </li>
                                <li>Supervisor:
                                    <strong><a href="http://www.ftn.uns.ac.rs/330739053/branislav-borovac">Branislav Borovac</a>
                                    </strong>
                                </li>
                            </ul>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
                <!-- Mini rover with gripper -->
    <div class="portfolio-modal modal fade" id="portfolioModal7" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <h2>Mini rover with gripper</h2>
                            <hr class="star-primary">
                            <img src="./img/portfolio/p1_imp.png" class="img-responsive img-centered" alt="">
                            <p>
                                For my BSc internship project, I have worked on a small, 4 wheel rover, with a mounted arm with a gripper. I have written C code for serial communication and execution of the tele-operated commands for:
                                <li>
                                    Operation of the 5 DOF robot arm with a gripping end-effector, in order to perform manipulation tasks.
                                </li>
                                <li>
                                    Communication with the rover’s motor and light drivers in order to perform driving  and signalling actions.
                                </li>

                            <img src="./img/portfolio_data/imp1.png" class="img-responsive img-centered" alt="">
                            <p>
                                The code was later extended for WiFi communication and the robot was used for a demonstration at the 2010 Science Festival in Belgrade.
                            </p>
                            <iframe width="560" height="315" src="https://www.youtube.com/embed/Ga4OSSYxXqw" frameborder="0" allowfullscreen></iframe>

                            <iframe width="560" height="315" src="https://www.youtube.com/embed/qgKcoUgNUcM" frameborder="0" allowfullscreen></iframe>



                            <ul class="list-inline item-details">
                                <li>Institution:
                                    <strong><a href="http://www.pupin.rs/RnDProfile/index.html">Robotics Centre, Mihajlo Pupin Institute</a>
                                    </strong>
                                </li>
                                <li>Date:
                                    <strong><a href="#">2010</a>
                                    </strong>
                                </li>
                                <li>Supervisor:
                                    <strong><a href="http://www.pupin.rs/RnDProfile/rodic.html">Aleksandar Rodić</a>
                                    </strong>
                                </li>
                            </ul>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- jQuery 
    <script src="vendor/jquery/jquery.min.js"></script>-->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript KOJI KURAC
    <script src="vendor/bootstrap/js/bootstrap.min.js"></script> -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>


    <!-- Plugin JavaScript -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>

    <!-- Contact Form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Theme JavaScript -->
    <script src="js/freelancer.min.js"></script>

</body>

</html>
